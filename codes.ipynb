{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 21:06:13 WARNING: Language fa package default expects mwt, which has been added\n",
      "2024-08-12 21:06:13 INFO: Loading these models for language: fa (Persian):\n",
      "==============================\n",
      "| Processor | Package        |\n",
      "------------------------------\n",
      "| tokenize  | perdt          |\n",
      "| mwt       | perdt          |\n",
      "| lemma     | perdt_nocharlm |\n",
      "==============================\n",
      "\n",
      "2024-08-12 21:06:13 INFO: Using device: cpu\n",
      "2024-08-12 21:06:13 INFO: Loading: tokenize\n",
      "2024-08-12 21:06:13 INFO: Loading: mwt\n",
      "2024-08-12 21:06:13 INFO: Loading: lemma\n",
      "2024-08-12 21:06:13 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "from Scripts.Configs.ConfigClass import Config\n",
    "from Scripts.DataManager.GraphConstructor.GraphConstructor import TextGraphType\n",
    "import os\n",
    "from Scripts.DataManager.GraphLoader.DigiKalaGraphDataModule import DigiKalaGraphDataModule\n",
    "import torch\n",
    "from torch.utils.flop_counter import FlopCounterMode\n",
    "root_path = %pwd\n",
    "config = Config(root_path)\n",
    "# config = Config(r'E:\\Darsi\\Payan Name Arshad\\Second Work\\ColorIntelligence2\\ColorIntelligence')\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.Models.GraphEmbedding.HeteroDeepGraphEmbedding4 import HeteroDeepGraphEmbedding4\n",
    "from Scripts.Models.GraphEmbedding.HeteroDeepGraphEmbedding5 import HeteroDeepGraphEmbedding5\n",
    "from Scripts.Models.GraphEmbedding.HeteroDeepGraphEmbedding6 import HeteroDeepGraphEmbedding6\n",
    "from Scripts.Models.GraphEmbedding.HeteroDeepGraphEmbedding8 import HeteroDeepGraphEmbedding8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.Models.LightningModels.LightningModels import HeteroMultiClassLightningModel\n",
    "from Scripts.Models.LossFunctions.HeteroLossFunctions import MulticlassHeteroLoss1, MulticlassHeteroLoss2, MulticlassHeteroLoss3\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import lightning as L\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from Scripts.Models.ModelsManager.ClassifierModelManager import ClassifierModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.2\n"
     ]
    }
   ],
   "source": [
    "print(stanza.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stanza.pipeline.core import DownloadMethod\n",
    "# token_lemma = stanza.Pipeline(\n",
    "#             \"fa\", download_method=DownloadMethod.REUSE_RESOURCES, processors=[\"tokenize\", \"lemma\"])\n",
    "# token_lemma.processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_sm\", disable=['ner', 'lemmatizer', 'attribute_ruler', 'parser', 'tagger', 'tok2vec'])\n",
    "\n",
    "# sample_texts = [\"text1\", \"text2a text2b text2c\", \"\", \"text3a, text3b\"]\n",
    "# sample_texts2 = []\n",
    "# for txt in sample_texts:\n",
    "#     doc = nlp(txt)\n",
    "#     tokens = [t.text for t in doc]\n",
    "#     while len(tokens)<2:\n",
    "#         tokens.append(\"#\")\n",
    "#     sample_texts2.append(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import clear_output\n",
    "# import pandas as pd\n",
    "# from stanza.pipeline.core import DownloadMethod\n",
    "# nlp = stanza.Pipeline(\"fa\", download_method=DownloadMethod.REUSE_RESOURCES, processors=\"tokenize\")\n",
    "# clear_output()\n",
    "# df = pd.read_csv(r'data\\DigiKala\\test_sm.csv', header=None)\n",
    "# df.columns = ['Text0', 'Score', 'Suggestion']\n",
    "# df.head()\n",
    "# texts2 = []\n",
    "# for row in df.Text0.values:\n",
    "#     doc = nlp(row)\n",
    "#     tokens = [t.text for sent in doc.sentences for t in sent.tokens]\n",
    "#     while len(tokens)<2:\n",
    "#         tokens.append(\"#\")\n",
    "#     texts2.append(' '.join(tokens))\n",
    "#     # if len(tokens) < 2:\n",
    "#           df['Text'] = texts2\n",
    "#     #     print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 21:06:27 WARNING: Language fa package default expects mwt, which has been added\n",
      "2024-08-12 21:06:27 INFO: Loading these models for language: fa (Persian):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | perdt   |\n",
      "| mwt       | perdt   |\n",
      "=======================\n",
      "\n",
      "2024-08-12 21:06:27 INFO: Using device: cpu\n",
      "2024-08-12 21:06:27 INFO: Loading: tokenize\n",
      "2024-08-12 21:06:27 INFO: Loading: mwt\n",
      "2024-08-12 21:06:27 INFO: Done loading processors!\n",
      "2024-08-12 21:07:09 WARNING: Language fa package default expects mwt, which has been added\n",
      "2024-08-12 21:07:10 INFO: Loading these models for language: fa (Persian):\n",
      "==============================\n",
      "| Processor | Package        |\n",
      "------------------------------\n",
      "| tokenize  | perdt          |\n",
      "| mwt       | perdt          |\n",
      "| pos       | perdt_charlm   |\n",
      "| lemma     | perdt_nocharlm |\n",
      "==============================\n",
      "\n",
      "2024-08-12 21:07:10 INFO: Using device: cpu\n",
      "2024-08-12 21:07:10 INFO: Loading: tokenize\n",
      "2024-08-12 21:07:10 INFO: Loading: mwt\n",
      "2024-08-12 21:07:10 INFO: Loading: pos\n",
      "2024-08-12 21:07:10 INFO: Loading: lemma\n",
      "2024-08-12 21:07:10 INFO: Done loading processors!\n",
      "2024-08-12 21:07:12 WARNING: Language fa package default expects mwt, which has been added\n",
      "2024-08-12 21:07:13 INFO: Loading these models for language: fa (Persian):\n",
      "==============================\n",
      "| Processor | Package        |\n",
      "------------------------------\n",
      "| tokenize  | perdt          |\n",
      "| mwt       | perdt          |\n",
      "| pos       | perdt_charlm   |\n",
      "| lemma     | perdt_nocharlm |\n",
      "==============================\n",
      "\n",
      "2024-08-12 21:07:13 INFO: Using device: cpu\n",
      "2024-08-12 21:07:13 INFO: Loading: tokenize\n",
      "2024-08-12 21:07:13 INFO: Loading: mwt\n",
      "2024-08-12 21:07:13 INFO: Loading: pos\n",
      "2024-08-12 21:07:13 INFO: Loading: lemma\n",
      "2024-08-12 21:07:13 INFO: Done loading processors!\n",
      " Creating Graphs :  31%|███       | 1001/3261 [04:51<10:58,  3.43it/s]"
     ]
    }
   ],
   "source": [
    "graph_type= TextGraphType.FULL\n",
    "data_manager = DigiKalaGraphDataModule(config, test_size=0.2, val_size=0.2, shuffle=False, start_data_load=0 , end_data_load = 3261 , device='cpu', batch_size=batch_size, graph_type=graph_type, load_preprocessed_data = False)\n",
    "data_manager.load_labels()\n",
    "data_manager.load_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData, Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hetero_data = torch.load(r'data\\GraphData\\DigiKala\\seq_gen\\0_1000_compressed.pt')\n",
    "# for i, hd in enumerate(all_hetero_data):\n",
    "    # print(i, hd['word'].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(12, 16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_manager.val_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import fasttext\n",
    "nlp = fasttext.load_model(config.fa.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 21:04:27 WARNING: Language fa package default expects mwt, which has been added\n",
      "2024-08-12 21:04:27 INFO: Loading these models for language: fa (Persian):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | perdt   |\n",
      "| mwt       | perdt   |\n",
      "=======================\n",
      "\n",
      "2024-08-12 21:04:27 INFO: Using device: cpu\n",
      "2024-08-12 21:04:27 INFO: Loading: tokenize\n",
      "2024-08-12 21:04:27 INFO: Loading: mwt\n",
      "2024-08-12 21:04:27 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "from stanza.pipeline.core import DownloadMethod\n",
    "nlp = stanza.Pipeline(\"fa\", download_method=DownloadMethod.REUSE_RESOURCES, processors='tokenize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(data_manager.test_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = data_manager.val_dataloader()\n",
    "X3, Y3 = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "metadata = copy(X3.metadata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['dep', 'tag', 'word', 'sentence', 'general', 'sentiment'], [('dep', 'dep_word', 'word'), ('word', 'word_dep', 'dep'), ('tag', 'tag_word', 'word'), ('word', 'word_tag', 'tag'), ('word', 'seq', 'word'), ('general', 'general_sentence', 'sentence'), ('sentence', 'sentence_general', 'general'), ('word', 'word_sentence', 'sentence'), ('sentence', 'sentence_word', 'word'), ('word', 'word_sentiment', 'sentiment'), ('sentiment', 'sentiment_word', 'word')])\n"
     ]
    }
   ],
   "source": [
    "_ = next(iter(data_manager.test_dataloader()))\n",
    "print(_[0].metadata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general:  4\n",
      "sentence:  21\n",
      "tensor([[ 0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  2,  3,  3,  3,  3,  3,  3,  3,\n",
      "          3,  3,  3],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20]])\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20],\n",
      "        [ 0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  2,  3,  3,  3,  3,  3,  3,  3,\n",
      "          3,  3,  3]])\n",
      "tensor([[  52, 1230],\n",
      "        [   1,    3]])\n"
     ]
    }
   ],
   "source": [
    "print('general: ', len(_[0]['general'].x))\n",
    "print('sentence: ', len(_[0]['sentence'].x))\n",
    "print(_[0][('general', 'general_sentence', 'sentence')].edge_index)\n",
    "print(_[0][('sentence', 'sentence_general', 'general')].edge_index)\n",
    "print(_[0][('word', 'word_sentiment', 'sentiment')].edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "edge_type_weights = {\n",
    "    'seq': [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "import torchmetrics\n",
    "\n",
    "def save_evaluation(model_mgr, eval_dataloader, name_prepend: str='',\n",
    "                 give_confusion_matrix: bool=True,\n",
    "                 give_report: bool=True,\n",
    "                 give_f1_score: bool=False,\n",
    "                 give_accuracy_score: bool=False,\n",
    "                 give_precision_score: bool=False,\n",
    "                 give_recall_score: bool=False,\n",
    "                 give_hinge_loss: bool=False,\n",
    "                 multi_class: bool=False\n",
    "                 ):\n",
    "\n",
    "        test_metrics_path = path.join(model_mgr.log_dir, model_mgr.log_name, f'version_{model_mgr.logger.version}', f'{name_prepend}_test_metrics.txt')\n",
    "\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        model_mgr.lightning_model.eval()\n",
    "        model_mgr.lightning_model.model.eval()\n",
    "        model_mgr.torch_model.eval()\n",
    "        for X, y in eval_dataloader:\n",
    "            model_mgr.trainer.model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_p = model_mgr.trainer.model(X.to(model_mgr.device))\n",
    "            if type(y_p) is tuple:\n",
    "                y_p = y_p[0]\n",
    "\n",
    "            if multi_class:\n",
    "                y_pred.append(y_p.detach().to(y.device))\n",
    "                y_true.append(y)\n",
    "            else:\n",
    "                y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "                y_true.append(y.to(torch.int32))\n",
    "        y_true = torch.concat(y_true)\n",
    "        y_pred = torch.concat(y_pred)\n",
    "        print(y_true.shape)\n",
    "        print(y_pred.shape)\n",
    "        if multi_class:\n",
    "            y_true_num = torch.argmax(y_true, dim=1)\n",
    "            y_pred_num = torch.argmax(y_pred, dim=1)\n",
    "        else:\n",
    "            y_true_num = y_true\n",
    "            y_pred_num = y_pred\n",
    "\n",
    "        print(y_true_num.shape)\n",
    "        print(y_pred_num.shape)\n",
    "        with open(test_metrics_path, 'at+') as f:\n",
    "            if(give_confusion_matrix):\n",
    "                print(f'confusion_matrix: \\n{confusion_matrix(y_true_num, y_pred_num)}', file=f)\n",
    "            if(give_report):\n",
    "                print(classification_report(y_true_num, y_pred_num), file=f)\n",
    "            if(give_f1_score):\n",
    "                if multi_class:\n",
    "                    print(f'f1_score: {f1_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                else:\n",
    "                    print(f'f1_score: {f1_score(y_true_num, y_pred_num)}', file=f)\n",
    "            if(give_accuracy_score):\n",
    "                print(f'accuracy_score: {accuracy_score(y_true_num, y_pred_num)}', file=f)\n",
    "            if(give_precision_score):\n",
    "                if multi_class:\n",
    "                    print(f'f1_score: {precision_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                else:\n",
    "                    print(f'f1_score: {precision_score(y_true_num, y_pred_num)}', file=f)\n",
    "            if(give_recall_score):\n",
    "                if multi_class:\n",
    "                    print(f'f1_score: {recall_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                else:\n",
    "                    print(f'f1_score: {recall_score(y_true_num, y_pred_num)}', file=f)\n",
    "            # if(give_hinge_loss):\n",
    "            #     print(f'hinge_loss: {hinge_loss(y_true_num, y_pred)}', file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x0000028E1308EA40>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(metadata[0].remove(x, inplace=True) for x in ['dep', 'tag', 'sentence', 'sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['dep', 'tag', 'word', 'sentence', 'general', 'sentiment'],\n",
       " [('dep', 'dep_word', 'word'),\n",
       "  ('word', 'word_dep', 'dep'),\n",
       "  ('tag', 'tag_word', 'word'),\n",
       "  ('word', 'word_tag', 'tag'),\n",
       "  ('word', 'seq', 'word'),\n",
       "  ('general', 'general_sentence', 'sentence'),\n",
       "  ('sentence', 'sentence_general', 'general'),\n",
       "  ('word', 'word_sentence', 'sentence'),\n",
       "  ('sentence', 'sentence_word', 'word'),\n",
       "  ('word', 'word_sentiment', 'sentiment'),\n",
       "  ('sentiment', 'sentiment_word', 'word')])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word', 'general']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in metadata[0] if x not in ['dep', 'tag', 'sentence', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dep', 'dep_word', 'word'),\n",
       " ('word', 'word_dep', 'dep'),\n",
       " ('tag', 'tag_word', 'word'),\n",
       " ('word', 'word_tag', 'tag'),\n",
       " ('word', 'seq', 'word'),\n",
       " ('general', 'general_sentence', 'sentence'),\n",
       " ('sentence', 'sentence_general', 'general'),\n",
       " ('word', 'word_sentence', 'sentence'),\n",
       " ('sentence', 'sentence_word', 'word'),\n",
       " ('word', 'word_sentiment', 'sentiment'),\n",
       " ('sentiment', 'sentiment_word', 'word')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in metadata[1] if x not in ['dep', 'tag', 'sentence', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in edge_type_weights:\n",
    "#     graph_embedding = HeteroDeepGraphEmbedding8(300, 2, metadata, 32, dropout=0.2, edge_type_count=2, edge_type_weights=edge_type_weights[k], active_keys = ['word','general'])\n",
    "#     graph_embedding = graph_embedding.to(device)\n",
    "\n",
    "#     flopt_counter = FlopCounterMode(graph_embedding)\n",
    "#     with flopt_counter:\n",
    "#         graph_embedding(X3.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import BatchNorm, MemPooling, to_hetero, PairNorm\n",
    "from torch_geometric.data import HeteroData\n",
    "from Scripts.Models.BaseModels.HeteroGat import HeteroGat\n",
    "from Scripts.Models.BaseModels.HeteroLinear import HeteroLinear\n",
    "\n",
    "class HeteroDeepGraphEmbedding6(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_feature: int, out_features: int,\n",
    "                 metadata,\n",
    "                 hidden_feature: int=256,\n",
    "                 device = 'cpu',\n",
    "                 dropout=0.1,\n",
    "                 edge_type_count=9,\n",
    "                 edge_type_weights=-1,\n",
    "                 active_keys = ['dep', 'tag', 'word', 'sentence', 'general'],\n",
    "                 num_pooling_classes=1\n",
    "                 ):\n",
    "\n",
    "        super(HeteroDeepGraphEmbedding6, self).__init__()\n",
    "        self.input_features = input_feature\n",
    "        self.num_out_features = out_features\n",
    "        self.hidden_feature: int = hidden_feature\n",
    "        self.edge_type_count = edge_type_count\n",
    "        self.edge_type_weights = torch.nn.Parameter(torch.tensor([1]* self.edge_type_count if edge_type_weights==-1 else  edge_type_weights).to(torch.float32), requires_grad=False)\n",
    "\n",
    "        self.part_weight_norm = torch.nn.LayerNorm((self.edge_type_count,))\n",
    "        self.norm = PairNorm()\n",
    "        self.drop = torch.nn.Dropout(0.2)\n",
    "        self.active_keys = active_keys\n",
    "\n",
    "        self.hetero_linear1 = to_hetero(HeteroLinear(self.input_features,self.hidden_feature, use_dropout=False, use_batch_norm=True), metadata)\n",
    "\n",
    "        self.hetero_gat_1 = to_hetero(HeteroGat(self.hidden_feature, self.hidden_feature, dropout, num_heads=2), metadata)\n",
    "        self.hetero_gat_2 = to_hetero(HeteroGat(self.hidden_feature, self.hidden_feature, dropout, num_heads=2), metadata)\n",
    "\n",
    "        self.hetero_linear_2 = to_hetero(HeteroLinear(self.hidden_feature, self.input_features, dropout, use_batch_norm=True), metadata)\n",
    "\n",
    "        self.num_pooling_classes = torch.nn.Parameter(torch.tensor(num_pooling_classes).to(torch.int32), requires_grad=False)\n",
    "        self.mem_pool = MemPooling(self.hidden_feature, self.hidden_feature, 2, self.num_pooling_classes)\n",
    "\n",
    "        self.linear_1 = Linear(self.hidden_feature* self.num_pooling_classes, self.hidden_feature)\n",
    "        self.linear_2 = Linear(self.hidden_feature, self.hidden_feature)\n",
    "        self.batch_norm_1 = BatchNorm(self.hidden_feature)\n",
    "\n",
    "        self.output_layer = Linear(self.hidden_feature, self.num_out_features)\n",
    "\n",
    "        self.dep_embedding = torch.nn.Embedding(200, self.input_features)\n",
    "        self.tag_embedding = torch.nn.Embedding(200, self.input_features)\n",
    "        self.dep_unembedding = torch.nn.Linear(self.hidden_feature, 200)\n",
    "        self.tag_unembedding = torch.nn.Linear(self.hidden_feature, 200)\n",
    "\n",
    "        self.pw1 = torch.nn.Parameter(torch.tensor(self.edge_type_weights, dtype=torch.float32), requires_grad=False)\n",
    "\n",
    "        self.x_batches = None\n",
    "        self.x_batches_cpu = None\n",
    "        self.x_dict_cpu_1 = None\n",
    "        self.x_dict_cpu_2 = None\n",
    "\n",
    "\n",
    "    def forward(self, x: HeteroData) -> Tensor:\n",
    "        self.x_batches = {k:x[k].batch for k in self.active_keys}\n",
    "        # self.x_batches_cpu = {k:self.x_batches[k].to('cpu') for k in self.active_keys}\n",
    "        x_dict, edge_attr_dict, edge_index_dict = self.preprocess_data(x)\n",
    "        edge_attr_dict = self.update_weights(edge_attr_dict, self.pw1)\n",
    "        x_dict = self.hetero_linear1(x_dict)\n",
    "        x_dict = self.hetero_gat_1(x_dict, edge_index_dict, edge_attr_dict)\n",
    "        # self.x_dict_cpu_1 = {k: x_dict[k].to('cpu') for k in x_dict}\n",
    "        self.normalize(x_dict, self.x_batches)\n",
    "        x_dict = self.hetero_gat_2(x_dict, edge_index_dict, edge_attr_dict)\n",
    "        # self.x_dict_cpu_2 = {k: x_dict[k].to('cpu') for k in x_dict}\n",
    "        x_pooled, S = self.mem_pool(x_dict['word'], self.x_batches['word'])\n",
    "\n",
    "        x_pooled = x_pooled.view(x_pooled.shape[0], -1)\n",
    "        x_pooled = F.relu(self.linear_1(x_pooled))\n",
    "        x_pooled = F.relu(self.batch_norm_1(self.linear_2(x_pooled)))\n",
    "        out = self.output_layer(x_pooled)\n",
    "\n",
    "        x_dict_out = self.hetero_linear_2(x_dict)\n",
    "        if 'dep' in x_dict_out:\n",
    "            x_dict_out['dep'] = self.dep_unembedding(x_dict['dep'])\n",
    "        if 'tag' in x_dict_out:\n",
    "            x_dict_out['tag'] = self.tag_unembedding(x_dict['tag'])\n",
    "\n",
    "        return out, x_dict_out\n",
    "\n",
    "    def preprocess_data(self, x):\n",
    "        x_dict = {key: x.x_dict[key] for key in x.x_dict}\n",
    "        if 'dep' in x_dict:\n",
    "            x_dict['dep'] = self.dep_embedding(x_dict['dep'])\n",
    "        if 'tag' in x_dict:\n",
    "            x_dict['tag'] = self.tag_embedding(x_dict['tag'])\n",
    "\n",
    "        edge_attr_dict = x.edge_attr_dict\n",
    "        edge_index_dict = x.edge_index_dict\n",
    "\n",
    "        return x_dict, edge_attr_dict, edge_index_dict\n",
    "\n",
    "    def normalize(self, x_dict, x_batches):\n",
    "        for k in self.active_keys:\n",
    "            vecs = x_dict[k]\n",
    "            if k not in x_batches:\n",
    "                print('k is not in x_batches')\n",
    "                continue\n",
    "            batches = x_batches[k]\n",
    "            if batches is None:\n",
    "                print('batches is none')\n",
    "                continue\n",
    "            if len(batches) == 0:\n",
    "                print('batches is empty')\n",
    "                continue\n",
    "\n",
    "            x_dict[k] = self.norm(vecs, batches)\n",
    "        return x_dict\n",
    "\n",
    "    def update_weights(self, edge_attr_dict, part_weights):\n",
    "        for i, key in enumerate(edge_attr_dict):\n",
    "            edge_attr = edge_attr_dict[key]\n",
    "            if edge_attr is None or edge_attr == ('word', 'seq', 'word'):\n",
    "                continue\n",
    "            edge_attr_dict[key]= edge_attr * part_weights[i]\n",
    "        return edge_attr_dict\n",
    "\n",
    "    def get_scale_same(self, scale:float, attributes: Tensor):\n",
    "        if attributes is None or len(attributes) == 0:\n",
    "            return\n",
    "        attributes = scale * torch.ones_like(attributes)\n",
    "        return attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from Scripts.Models.LossFunctions.HeteroLossArgs import HeteroLossArgs\n",
    "\n",
    "\n",
    "class MulticlassHeteroLoss2(torch.nn.Module):\n",
    "    def __init__(self, exception_keys: List[str], enc_factor=0.0, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.cel_loss=  torch.nn.CrossEntropyLoss()\n",
    "        self.mse_loss = torch.nn.MSELoss()\n",
    "        self.exception_keys = exception_keys\n",
    "        self.enc_factor = enc_factor\n",
    "\n",
    "    def forward(self, out_pred: HeteroLossArgs, out_main: HeteroLossArgs):\n",
    "        loss = self.cel_loss(out_pred.y, out_main.y)\n",
    "        x_dict_keys = [k for k in out_pred.x_dict.keys() if k not in self.exception_keys]\n",
    "\n",
    "        for key in x_dict_keys:\n",
    "            tensor1 = out_pred.x_dict[key]\n",
    "            tensor2 = out_main.x_dict[key]\n",
    "            if tensor2.ndim == 1 and tensor2.dtype is torch.long:\n",
    "                tensor2 = torch.nn.functional.one_hot(input=tensor2.to(torch.long), num_classes=tensor1.shape[1]).to(torch.float32)\n",
    "            loss += self.enc_factor * (self.mse_loss(tensor1, tensor2))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['dep', 'tag', 'word', 'sentence', 'general', 'sentiment'],\n",
       " [('dep', 'dep_word', 'word'),\n",
       "  ('word', 'word_dep', 'dep'),\n",
       "  ('tag', 'tag_word', 'word'),\n",
       "  ('word', 'word_tag', 'tag'),\n",
       "  ('word', 'seq', 'word'),\n",
       "  ('general', 'general_sentence', 'sentence'),\n",
       "  ('sentence', 'sentence_general', 'general'),\n",
       "  ('word', 'word_sentence', 'sentence'),\n",
       "  ('sentence', 'sentence_word', 'word'),\n",
       "  ('word', 'word_sentiment', 'sentiment'),\n",
       "  ('sentiment', 'sentiment_word', 'word')])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fardin Rastakhiz @ 2023\n",
    "\n",
    "\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "\n",
    "class HeteroLinear(nn.Module):\n",
    "\n",
    "    def __init__(self, in_feature, out_feature, dropout = 0.2, use_dropout=True, use_batch_norm=False, use_activation=True) -> None:\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_feature, out_feature)\n",
    "        self.batch_norm = BatchNorm(out_feature)\n",
    "        self.dropout= nn.Dropout(dropout)\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.use_dropout = use_dropout\n",
    "        self.use_activation=use_activation\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "\n",
    "        x = self.linear(x)\n",
    "        if self.use_batch_norm:\n",
    "            x = self.batch_norm(x)\n",
    "        if self.use_activation:\n",
    "            x = F.leaky_relu(x)\n",
    "        if self.use_dropout:\n",
    "            x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\razieh\\AppData\\Local\\Temp\\ipykernel_15880\\1102389976.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.pw1 = torch.nn.Parameter(torch.tensor(self.edge_type_weights, dtype=torch.float32), requires_grad=False)\n",
      "c:\\Users\\razieh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "c:\\Users\\razieh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:198: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type                      | Params\n",
      "--------------------------------------------------------\n",
      "0 | model     | HeteroDeepGraphEmbedding6 | 307 K \n",
      "1 | loss_func | MulticlassHeteroLoss2     | 0     \n",
      "2 | train_acc | MulticlassAccuracy        | 0     \n",
      "3 | val_acc   | MulticlassAccuracy        | 0     \n",
      "4 | test_acc  | MulticlassAccuracy        | 0     \n",
      "--------------------------------------------------------\n",
      "307 K     Trainable params\n",
      "23        Non-trainable params\n",
      "307 K     Total params\n",
      "1.228     Total estimated model params size (MB)\n",
      "c:\\Users\\razieh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\razieh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\utilities\\data.py:104: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n",
      "c:\\Users\\razieh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\utilities\\data.py:104: Total length of `CombinedLoader` across ranks is zero. Please make sure this was your intention.\n",
      "`Trainer.fit` stopped: No training batches.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\razieh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\razieh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\razieh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\razieh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    for k in edge_type_weights:\n",
    "        graph_embedding = HeteroDeepGraphEmbedding6(300, 3, metadata, 32, dropout=0.1, edge_type_count=2, edge_type_weights=edge_type_weights[k], active_keys=['word', 'general'])\n",
    "        graph_embedding = graph_embedding.to(device)\n",
    "        callbacks = [\n",
    "        ModelCheckpoint(save_top_k=5, mode='max', monitor='val_acc', save_last=True)\n",
    "        ]\n",
    "        loss_func = MulticlassHeteroLoss2(exception_keys=['word'], enc_factor=0.0003)\n",
    "        optimizer = torch.optim.Adam(graph_embedding.parameters(), lr=0.0045, weight_decay=0.00125)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[6, 13, 28, 45, 60], gamma=0.5, verbose=True)\n",
    "        lightning_model = HeteroMultiClassLightningModel(graph_embedding, 4,\n",
    "                                            optimizer=optimizer,\n",
    "                                            loss_func=loss_func,\n",
    "                                            learning_rate=0.045,\n",
    "                                            batch_size=batch_size,\n",
    "                                            user_lr_scheduler=True,\n",
    "                                            lr_scheduler=lr_scheduler,\n",
    "                                            min_lr=0.0005\n",
    "                                            ).to(device)\n",
    "        lightning_model.model.to(device)\n",
    "\n",
    "        model_manager = ClassifierModelManager(graph_embedding, lightning_model, log_name='hetero_model_20_AG',device=device, num_train_epoch=120)\n",
    "        model_manager.fit(datamodule=data_manager)\n",
    "        # model_manager.save_plot_csv_logger(loss_names=['train_loss_epoch', 'val_loss'], eval_names=['train_acc_epoch', 'val_acc'], name_prepend=f'tests_{i}_{k}')\n",
    "        model_manager.torch_model = model_manager.torch_model.to(device)\n",
    "        save_evaluation(model_manager, data_manager.val_dataloader(), f'{i}_{k}',True, True, True, True, True, True, True, multi_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, hinge_loss\n",
    "import torchmetrics\n",
    "\n",
    "def save_evaluation(model_mgr, l_model, eval_dataloader, name_prepend: str='',\n",
    "                 give_confusion_matrix: bool=True,\n",
    "                 give_report: bool=True,\n",
    "                 give_f1_score: bool=False,\n",
    "                 give_accuracy_score: bool=False,\n",
    "                 give_precision_score: bool=False,\n",
    "                 give_recall_score: bool=False,\n",
    "                 give_hinge_loss: bool=False,\n",
    "                 multi_class: bool=False\n",
    "                 ):\n",
    "\n",
    "        test_metrics_path = path.join(model_mgr.log_dir, model_mgr.log_name, f'version_{model_mgr.logger.version}', f'{name_prepend}_test_metrics.txt')\n",
    "\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for X, y in eval_dataloader:\n",
    "            l_model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_p = l_model(X.to(model_mgr.device))\n",
    "            if type(y_p) is tuple:\n",
    "                y_p = y_p[0]\n",
    "\n",
    "            if multi_class:\n",
    "                y_pred.append(y_p.detach().to(y.device))\n",
    "                y_true.append(y)\n",
    "            else:\n",
    "                y_pred.append((y_p>0).to(torch.int32).detach().to(y.device))\n",
    "                y_true.append(y.to(torch.int32))\n",
    "        y_true = torch.concat(y_true)\n",
    "        y_pred = torch.concat(y_pred)\n",
    "        print(y_true.shape)\n",
    "        print(y_pred.shape)\n",
    "        if multi_class:\n",
    "            y_true_num = torch.argmax(y_true, dim=1)\n",
    "            y_pred_num = torch.argmax(y_pred, dim=1)\n",
    "        else:\n",
    "            y_true_num = y_true\n",
    "            y_pred_num = y_pred\n",
    "\n",
    "        print(y_true_num.shape)\n",
    "        print(y_pred_num.shape)\n",
    "        with open(test_metrics_path, 'at+') as f:\n",
    "            if(give_confusion_matrix):\n",
    "                print(f'confusion_matrix: \\n{confusion_matrix(y_true_num, y_pred_num)}', file=f)\n",
    "            if(give_report):\n",
    "                print(classification_report(y_true_num, y_pred_num), file=f)\n",
    "            if(give_f1_score):\n",
    "                if multi_class:\n",
    "                    print(f'f1_score: {f1_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                else:\n",
    "                    print(f'f1_score: {f1_score(y_true_num, y_pred_num)}', file=f)\n",
    "            if(give_accuracy_score):\n",
    "                print(f'accuracy_score: {accuracy_score(y_true_num, y_pred_num)}', file=f)\n",
    "            if(give_precision_score):\n",
    "                if multi_class:\n",
    "                    print(f'f1_score: {precision_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                else:\n",
    "                    print(f'f1_score: {precision_score(y_true_num, y_pred_num)}', file=f)\n",
    "            if(give_recall_score):\n",
    "                if multi_class:\n",
    "                    print(f'f1_score: {recall_score(y_true_num, y_pred_num, average=None)}', file=f)\n",
    "                else:\n",
    "                    print(f'f1_score: {recall_score(y_true_num, y_pred_num)}', file=f)\n",
    "            # if(give_hinge_loss):\n",
    "            #     print(f'hinge_loss: {hinge_loss(y_true_num, y_pred)}', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\razieh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\razieh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\razieh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\razieh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\razieh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\razieh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\razieh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\razieh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "save_evaluation(model_manager, lightning_model, data_manager.test_dataloader(), 'chpt_n',True, True, True, True, True, True, True, multi_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [nlp(tx) for tx in data_manager.df['Text']]\n",
    "doc_tokens = [[t.text for sent in doc.sentences for t in sent.tokens] for doc in docs]\n",
    "lengths = [len(ts) for ts in doc_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_leghts = [data[0]['word'].x.shape[0] for data in data_manager.dataset[graph_type]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (1, 1),\n",
       " (2, 2),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (2, 2),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = (data_manager.df.Suggestion.values-1).tolist()\n",
    "list2 = torch.argmax(data_manager.labels, dim=1).tolist()\n",
    "[(list1[i], list2[i]) for i in range(len(list1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict(zip(lengths, graph_leghts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
