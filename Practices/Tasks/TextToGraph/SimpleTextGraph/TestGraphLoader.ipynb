{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fardin Rastakhiz @2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from Scripts.Configs.ConfigClass import Config\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split, T_co\n",
    "from torch_geometric.data.lightning import LightningDataset\n",
    "import pdb\n",
    "import lightning as L\n",
    "import time\n",
    "from Scripts.DataManager.GraphConstructor.CoOccurrenceGraphConstructor import CoOccurrenceGraphConstructor\n",
    "from Scripts.DataManager.GraphLoader.GLabeledGraphLoader import GLabeledGraphLoader\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer('english')\n",
    "config = Config(r'C:\\Users\\fardin\\Projects\\ColorIntelligence\\Scripts\\Configs\\Config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r'C:\\Users\\fardin\\Projects\\ColorIntelligence\\data\\DigiKala\\train_sm.csv')\n",
    "test_df = pd.read_csv(r'C:\\Users\\fardin\\Projects\\ColorIntelligence\\data\\DigiKala\\test_sm.csv')\n",
    "train_df.columns = ['Polarity', 'Title', 'Review']\n",
    "test_df.columns = ['Polarity', 'Title', 'Review']\n",
    "train_df = train_df[['Polarity', 'Review']]\n",
    "test_df = test_df[['Polarity', 'Review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time in second: 0.009000062942504883\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "graph_const = CoOccurrenceGraphConstructor(train_df['Review'], 'AmazonReview', config, lazy_construction=True,  load_preprocessed_data=True, naming_prepend='graph')\n",
    "print(f'execution time in second: {time.time() - start_time}')\n",
    "# graph_const = CoOccurrenceGraphConstructor(train_df['Review'][:10], 'AmazonReview', config, lazy_construction=False, naming_prepend='graph', load_preprocessed_data=False)\n",
    "# graph = graph_const.to_graph(train_df['Review'][0])\n",
    "# graph_const.draw_graph(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = torch.tensor(test_df['Polarity'].apply(lambda p: 0 if p==1 else 1), dtype=torch.float32).view(-1,1)\n",
    "graph_loader = GLabeledGraphLoader(graph_const, labels[:10],2, 'cpu', val_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import torch\n",
    "from pytorch_lightning.utilities.types import OptimizerLRScheduler, STEP_OUTPUT\n",
    "import lightning as L\n",
    "from torch_geometric.nn import  GCNConv\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data_loader = graph_loader.get_train_data()\n",
    "X, y = next(iter(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[59.3724],\n",
       "        [43.7305]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Scripts.Models.ClassifierModels.GraphAutoEncoderModel1 import GraphAutoEncoderModel1\n",
    "autoencoder_model = GraphAutoEncoderModel1(300, 1)\n",
    "autoencoder_model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from Scripts.Models.LightningModels.LightningClassifier1 import BinaryLightningModel\n",
    "\n",
    "autoencoder_model = GraphAutoEncoderModel1(300, 1)\n",
    "lightning_model = BinaryLightningModel(autoencoder_model,\n",
    "\n",
    "class LightningModel(L.LightningModule):\n",
    "\n",
    "    def __init__(self, model, optimizer, loss_func):\n",
    "        super(LightningModel, self).__init__()\n",
    "        self.optimizer = optimizer\n",
    "        self.model = model\n",
    "        self.loss_func = loss_func\n",
    "        if model.num_out_features > 2:\n",
    "            self.train_acc = torchmetrics.Accuracy(task=\"multiclass\")\n",
    "            self.val_acc = torchmetrics.Accuracy(task=\"multiclass\")\n",
    "            self.test_acc = torchmetrics.Accuracy(task=\"multiclass\")\n",
    "        else:\n",
    "            self.train_acc = torchmetrics.Accuracy(task=\"binary\")\n",
    "            self.val_acc = torchmetrics.Accuracy(task=\"binary\")\n",
    "            self.test_acc = torchmetrics.Accuracy(task=\"binary\")\n",
    "\n",
    "\n",
    "    def forward(self, data_batch, *args, **kwargs):\n",
    "        return self.model(data_batch)\n",
    "\n",
    "    def training_step(self, data_batch, *args, **kwargs) :\n",
    "        data, labels = data_batch\n",
    "        logits = self(data)\n",
    "        loss = self.loss_func(logits, labels.view(logits.shape))\n",
    "        self.log('training_loss', loss)\n",
    "\n",
    "        predicted_labels = logits if logits.shape[1] < 2 else torch.argmax(logits, dim=1)\n",
    "        self.train_acc(predicted_labels, labels.view(predicted_labels.shape))\n",
    "        self.log('training_acc', self.train_acc, prog_bar=True, on_epoch=True, on_step=False)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, data_batch, *args, **kwargs):\n",
    "        data, labels = data_batch\n",
    "        logits = self(data)\n",
    "        loss = self.loss_func(logits, labels.view(logits.shape))\n",
    "        self.log('val_loss', loss)\n",
    "\n",
    "        predicted_labels = logits if logits.shape[1] < 2 else torch.argmax(logits, dim=1)\n",
    "        self.val_acc(predicted_labels, labels.view(predicted_labels.shape))\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True, on_epoch=True, on_step=False)\n",
    "\n",
    "    # def test_step(self, data_batch, *args: Any, **kwargs: Any) -> STEP_OUTPUT:\n",
    "    #     data, labels = data_batch\n",
    "    #     pred_labels = self(data)\n",
    "    #     loss = self.loss_func(pred_labels, labels)\n",
    "    #     self.log('test_loss', loss)\n",
    "\n",
    "    def predict_step(self, data_batch, *args: Any, **kwargs: Any) -> Any:\n",
    "        data, labels = data_batch\n",
    "        return self(data)\n",
    "\n",
    "    def configure_optimizers(self) -> OptimizerLRScheduler:\n",
    "        return self.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "autoencoder_model = GraphAutoEncoderModel(300, 1)\n",
    "lightning_model = LightningModel(autoencoder_model,\n",
    "                                 torch.optim.Adam(autoencoder_model.parameters(), lr=0.001, weight_decay=0.005), nn.BCEWithLogitsLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                   | Params\n",
      "-----------------------------------------------------\n",
      "0 | model     | GraphAutoEncoderModel1 | 245 K \n",
      "1 | loss_func | BCEWithLogitsLoss      | 0     \n",
      "2 | train_acc | BinaryAccuracy         | 0     \n",
      "3 | val_acc   | BinaryAccuracy         | 0     \n",
      "4 | test_acc  | BinaryAccuracy         | 0     \n",
      "-----------------------------------------------------\n",
      "245 K     Trainable params\n",
      "0         Non-trainable params\n",
      "245 K     Total params\n",
      "0.983     Total estimated model params size (MB)\n",
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:293: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98a717d31f64daa8ff3f783645e3904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a11c60014924cea8ef464fabf7f814a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fardin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\utilities\\data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 144. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae8b25477454b5b8c0bc82dfb630fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963b5a6acd4140e0be74b1cbc981981c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593a6e6469794125b6815034e8816b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0dc28b543f4759b1c9975295dc6353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051bb6a62ea04704be2d28b1fcad6918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0df39eb61b4d6aa4cb4d5efe49593d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f421dc342346c48320b4638cac8ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0edac42ffe74561944aecc7d367f7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d23a924d7a1434f9ef2f33780a0eaea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=10, accelerator='gpu', devices=1, num_sanity_val_steps=0)\n",
    "trainer.fit(lightning_model, graph_loader.get_train_data(), graph_loader.get_val_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.]])\n",
      "tensor([[-26.4988],\n",
      "        [ -5.2990]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(graph_loader.get_test_data()))\n",
    "print(y)\n",
    "print(lightning_model(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-66.1845],\n",
       "        [ 17.6578]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = graph_loader.get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X, y = next(iter(train_data))\n",
    "module_0 = GCNConv(300, 256)\n",
    "output = module_0(X.x, X.edge_index, X.edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "output2 = [output[:X[0].x.shape[0]], output[X[0].x.shape[0]:X[1].x.shape[0]], output[X[1].x.shape[0]:X[2].x.shape[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(X is torch_geometric.data.batch.Batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gcn_conv = GCNConv(256, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# s = gcn_conv(output2[0], X[0].edge_index)\n",
    "# adj = torch.sparse_coo_tensor(X[0].edge_index, X[0].edge_attr).to_dense()\n",
    "# output3 = dense_diff_pool(output2[0], adj, s=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from flags import Flags\n",
    "class SampleGraph(Flags):\n",
    "    val1 = 1\n",
    "    val2 = 2\n",
    "    val3 = 4\n",
    "    val4 = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample: SampleGraph = SampleGraph.val4 | SampleGraph.val3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SampleGraph.val4 == sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
