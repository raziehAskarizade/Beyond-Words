{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import stanza\n",
    "import torch\n",
    "import numpy as np\n",
    "from stanza.pipeline.core import DownloadMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 11:17:01 WARNING: Language fa package default expects mwt, which has been added\n",
      "2024-08-25 11:17:03 INFO: Loading these models for language: fa (Persian):\n",
      "==============================\n",
      "| Processor | Package        |\n",
      "------------------------------\n",
      "| tokenize  | perdt          |\n",
      "| mwt       | perdt          |\n",
      "| pos       | perdt_charlm   |\n",
      "| lemma     | perdt_nocharlm |\n",
      "| depparse  | perdt_charlm   |\n",
      "==============================\n",
      "\n",
      "2024-08-25 11:17:03 INFO: Using device: cuda\n",
      "2024-08-25 11:17:03 INFO: Loading: tokenize\n",
      "2024-08-25 11:17:07 INFO: Loading: mwt\n",
      "2024-08-25 11:17:07 INFO: Loading: pos\n",
      "2024-08-25 11:17:08 INFO: Loading: lemma\n",
      "2024-08-25 11:17:08 INFO: Loading: depparse\n",
      "2024-08-25 11:17:09 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "token_lemma = stanza.Pipeline(\"fa\", download_method=DownloadMethod.REUSE_RESOURCES, processors=[\"tokenize\", \"lemma\", \"pos\", \"depparse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependencies = ['acl', 'acl:relcl', 'advcl', 'advcl:relcl', 'advmod', 'advmod:emph', 'advmod:lmod', 'amod', 'appos', 'aux', 'aux:pass', 'case', 'cc', 'cc:preconj', 'ccomp', 'clf', 'compound', 'compound:lvc', 'compound:prt', 'compound:redup', 'compound:svc', 'conj', 'cop', 'csubj', 'csubj:outer', 'csubj:pass', 'dep', 'det', 'det:numgov', 'det:nummod', 'det:poss', 'discourse', 'dislocated', 'expl', 'expl:impers', 'expl:pass', 'expl:pv', 'fixed', 'flat', 'flat:foreign', 'flat:name', 'goeswith', 'iobj', 'list', 'mark', 'nmod', 'nmod:poss', 'nmod:tmod', 'nsubj', 'nsubj:outer', 'nsubj:pass', 'nummod', 'nummod:gov', 'obj', 'obl', 'obl:agent', 'obl:arg', 'obl:lmod', 'obl:tmod', 'orphan', 'parataxis', 'punct', 'reparandum', 'root', 'vocative', 'xcomp']\n",
    "\n",
    "dep_idx = {d:idx for idx, d in enumerate(dependencies)}\n",
    "idx_dep = {idx:d for idx, d in enumerate(dependencies)}\n",
    "dep_range = torch.arange(0, len(dependencies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"data\\DigiKala\\train_sm.csv\", header=None)\n",
    "token_list = token_lemma(df[0].values[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_sentences = []\n",
    "doc = []\n",
    "for text in df[0].values:\n",
    "    token_list = token_lemma(text)\n",
    "    for idx, sentence in enumerate(token_list.sentences):\n",
    "        doc_sentences.append((sentence.text, sentence.tokens[0].text, idx))\n",
    "        for word in sentence.words:\n",
    "            doc.append((idx, word.text, word.lemma,\n",
    "                        word.upos, word.head, word.deprel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\Students\\Beyond_Words2\\find_most_used_deps_and_tags.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/Students/Beyond_Words2/find_most_used_deps_and_tags.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pd\u001b[39m.\u001b[39mDataFrame(np\u001b[39m.\u001b[39marray([doc[i][\u001b[39m3\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(doc))]))\u001b[39m.\u001b[39mvalue_counts()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(np.array([doc[i][3] for i in range(len(doc))])).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array([doc[i][5] for i in range(len(doc))])).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
